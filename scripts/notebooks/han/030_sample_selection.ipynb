{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29c9fb80-5fcc-4d0c-8b16-e513593a3f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "import json\n",
    "import msgpack\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323d238e-7cb4-4133-af39-9472a927b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../kcg-ml-image-pipeline/'))\n",
    "from utility.active_learning.samples import representative_sample_selection, get_min_distance_to_representative_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2c7fd9-2b5c-48ad-b795-71498d0c0932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT = '../dataset/'\n",
    "\n",
    "DATASETs = [\n",
    "    'environmental', \n",
    "    'character', \n",
    "    'icons', \n",
    "    'mech', \n",
    "    'waifu',\n",
    "    'propaganda-poster'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92577e18-973e-4536-8eea-8ea05b3bfb8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_representative_samples(dataset_name):\n",
    "    \n",
    "    # load clip vision embedding\n",
    "    \n",
    "    js = json.load(open(f'data/{dataset_name}/data.json'))\n",
    "    \n",
    "    job_uuids = list()\n",
    "    file_paths = list()\n",
    "    samples = list()\n",
    "    \n",
    "    for info in tqdm(js.values(), total=len(js), leave=False):\n",
    "    \n",
    "        file_path = os.path.splitext(info['file_path'].split('_')[0])[0]\n",
    "        \n",
    "        path = os.path.join(ROOT, 'clip', f'{file_path}_clip.msgpack')\n",
    "    \n",
    "        with open(path, 'rb') as f:\n",
    "            mp = msgpack.load(f)\n",
    "    \n",
    "        job_uuids.append(info['job_uuid'])\n",
    "        file_paths.append(file_path)\n",
    "        samples.append(np.array(mp['clip-feature-vector']))\n",
    "    \n",
    "    job_uuids = np.array(job_uuids)\n",
    "    samples = np.concatenate(samples, axis=0)\n",
    "    \n",
    "    path_to_index = {file_path: i for i, file_path in enumerate(file_paths)}\n",
    "    \n",
    "    # load rank data\n",
    "    \n",
    "    paths = sorted(glob.glob(os.path.join(ROOT, 'ranking', dataset_name, '*.json')))\n",
    "    \n",
    "    rank_file_paths = list()\n",
    "    \n",
    "    for path in tqdm(paths, leave=False):\n",
    "        js = json.load(open(path))\n",
    "    \n",
    "        if js['task'] != 'selection':\n",
    "            continue\n",
    "        \n",
    "        file_path_1 = os.path.splitext(js['image_1_metadata']['file_path'])[0].replace('datasets/', '')\n",
    "        file_path_2 = os.path.splitext(js['image_2_metadata']['file_path'])[0].replace('datasets/', '')\n",
    "        \n",
    "        if (file_path_1 not in path_to_index) or (file_path_2 not in path_to_index):\n",
    "            continue\n",
    "        rank_file_paths.append(file_path_1)\n",
    "        rank_file_paths.append(file_path_2)\n",
    "    \n",
    "    rank_file_paths = set(rank_file_paths)\n",
    "    \n",
    "    file_path = f'./data/{dataset_name}/representative.json'\n",
    "    \n",
    "    # continue\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        \n",
    "        existed = json.load(open(file_path))\n",
    "        \n",
    "        rank_file_paths = rank_file_paths.difference(existed['representative']).difference(existed['unused'])\n",
    "        \n",
    "        selected_indices = list(map(path_to_index.get, existed['representative']))\n",
    "        existed_samples = samples[selected_indices]\n",
    "    \n",
    "        existed_representative = existed['representative']\n",
    "        existed_unused = existed['unused']\n",
    "    \n",
    "    else:\n",
    "        existed_samples = None\n",
    "    \n",
    "        existed_representative = []\n",
    "        existed_unused = []\n",
    "    \n",
    "    indices = np.array(list(map(path_to_index.get, rank_file_paths)))\n",
    "    \n",
    "    #\n",
    "    \n",
    "    selected = representative_sample_selection(samples=samples[indices], threshold=0.25, existed_samples=existed_samples)\n",
    "        \n",
    "    # save\n",
    "    \n",
    "    representative_indices = indices[selected]\n",
    "    unused_indices = indices[list(set(range(len(indices))).difference(selected))]\n",
    "    \n",
    "    representative_names = [file_paths[i] for i in representative_indices] + existed_representative\n",
    "    unused_names = [file_paths[i] for i in unused_indices] + existed_unused\n",
    "    \n",
    "    json.dump({\n",
    "        'representative': representative_names,\n",
    "        'unused': unused_names\n",
    "    }, open(f'./data/{dataset_name}/representative.json', 'wt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7670a0ad-046c-4cd5-9e3a-dc12eccdedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in DATASETs:\n",
    "    save_representative_samples(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e0b5a6-2486-4565-aa68-a20f775bdcc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Environment",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
